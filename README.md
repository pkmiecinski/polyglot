# Polyglot - Edge AI Translation Device PoC

A Proof of Concept for an Edge AI translation device using:
- **Qwen3-ASR** for automatic speech recognition and language detection
- **NLLB-200** for multilingual translation (200 languages)
- **XTTS-v2** for text-to-speech with voice cloning

## Features

- **Real-time microphone input**: Captures audio from your microphone
- **Automatic language detection**: Identifies 52 languages and dialects
- **Speech transcription**: High-quality ASR using Qwen3-ASR-1.7B
- **Multilingual translation**: Translate between 200 languages with NLLB-200
- **Text-to-Speech**: Speak translations aloud with XTTS-v2 (17 languages)
- **Voice cloning**: Clone any voice with just a 6-second audio sample
- **Edge-ready**: Designed for local/edge deployment

## Supported Languages

### ASR (Qwen3-ASR)
30 languages including Chinese, English, Cantonese, Arabic, German, French, Spanish, Portuguese, Indonesian, Italian, Korean, Russian, Thai, Vietnamese, Japanese, Turkish, Hindi, Malay, Dutch, Swedish, and more.

### Translation (NLLB-200)
200 languages including:
- **Polish** âœ… and **Thai** âœ…
- All major European, Asian, Middle Eastern, and African languages

## Requirements

- Python 3.12+
- CUDA-capable GPU (recommended) or CPU
- PyTorch with CUDA support (for GPU acceleration)
- PortAudio (for microphone input)

## Installation

### 1. Install system dependencies (macOS)

```bash
brew install portaudio
```

### 2. Create virtual environment

```bash
conda create -n polyglot python=3.12 -y
conda activate polyglot
```

### 3. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 4. Setup TTS environment (separate venv due to dependency conflicts)

```bash
python3.10 -m venv .venv-tts
.venv-tts/bin/pip install TTS 'torch<2.6' 'torchaudio<2.6' 'transformers<4.46'
```

### 5. (Optional) Install FlashAttention for faster inference

```bash
pip install -U flash-attn --no-build-isolation
```

## Usage

### Basic transcription app

```bash
python main.py
```

### With translation

```bash
# Transcribe and translate to English
python main.py --continuous --translate English

# Translate to Polish
python main.py -c -T Polish

# Translate to Thai
python main.py -c -T Thai
```

### With speech output (TTS)

```bash
# Translate and speak the result
python main.py --continuous --translate English --speak

# Use voice cloning (provide 6+ second sample)
python main.py -c -T English --speak --voice my_voice.wav

# Save spoken audio to file
python main.py -c -T English --speak --save-audio output.wav
```

### Other options

```bash
# Use smaller model for faster inference
python main.py --model Qwen/Qwen3-ASR-0.6B

# Force specific language (skip auto-detection)
python main.py --language English

# Adjust recording duration
python main.py --duration 10

# Use CPU instead of GPU
python main.py --device cpu

# Loop mode - keep recording and translating
python main.py --loop --continuous --translate English
```

## Project Structure

```
polyglot/
â”œâ”€â”€ main.py              # Main application entry point
â”œâ”€â”€ audio_capture.py     # Microphone audio capture utilities
â”œâ”€â”€ transcriber.py       # Qwen3-ASR transcription wrapper
â”œâ”€â”€ translator.py        # NLLB-200 translation wrapper
â”œâ”€â”€ tts.py               # XTTS-v2 text-to-speech wrapper
â”œâ”€â”€ tts_worker.py        # TTS subprocess worker (runs in .venv-tts)
â”œâ”€â”€ .venv-tts/           # Separate venv for TTS (created during setup)
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ docs/                # Documentation
â”‚   â”œâ”€â”€ TRANSLATION_MODELS_RESEARCH.md
â”‚   â””â”€â”€ TTS_MODELS_RESEARCH.md
â””â”€â”€ README.md            # This file
```

## How It Works

1. **Audio Capture**: Records audio from the microphone at 16kHz sample rate
2. **Preprocessing**: Converts audio to the format expected by Qwen3-ASR
3. **Language Detection**: Model automatically identifies the spoken language
4. **Transcription**: Generates text transcript of the spoken audio
5. **Translation** (optional): NLLB-200 translates to your target language
6. **Speech Output** (optional): XTTS-v2 speaks the translation aloud

```
ðŸŽ¤ Audio â†’ [Qwen3-ASR] â†’ Text + Language â†’ [NLLB-200] â†’ Translated Text â†’ [XTTS-v2] â†’ ðŸ”Š Speech
```

## Models Used

| Component | Model | Size | Languages |
|-----------|-------|------|-----------|
| ASR | Qwen3-ASR-1.7B | ~4.7GB | 52 |
| Translation | NLLB-200-distilled-600M | ~1.2GB | 200 |
| TTS | XTTS-v2 | ~1.9GB | 17 |

### TTS Supported Languages (XTTS-v2)
English, Spanish, French, German, Italian, Portuguese, **Polish**, Turkish, Russian, Dutch, Czech, Arabic, Chinese, Japanese, Hungarian, Korean, Hindi

**Voice cloning**: Provide a 6+ second audio sample to clone any voice!

## License

Apache 2.0 (same as Qwen3-ASR model)
CC-BY-NC for NLLB-200
CPML for XTTS-v2 (Coqui Public Model License)
